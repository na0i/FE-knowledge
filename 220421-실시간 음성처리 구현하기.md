### 220421

#### 실시간 음성처리 구현하기

##### 참고한 사이트

> https://velog.io/@h-yes-oo/%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%94%EB%93%9C%EC%97%90%EC%84%9C-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%9D%8C%EC%84%B1-%EC%B2%98%EB%A6%AC-%EA%B0%9C%EB%B0%9C%EA%B8%B0-1-%EC%82%AC%EC%9A%A9%EC%9E%90%EC%9D%98-%EC%9D%8C%EC%84%B1-%EB%85%B9%EC%9D%8C%ED%95%98%EA%B8%B0
>
> https://nachwon.github.io/WebAudioAPI/
>
> https://developer.mozilla.org/ko/docs/Web/API/Web_Audio_API/Using_AudioWorklet

<br>

##### getUserMedia

> https://developer.mozilla.org/ko/docs/Web/API/MediaDevices/getUserMedia

- 사용자에게 미디어 입력 장치 사용 권한을 요청
- 사용자가 수락하면 요청한 미디어 종류의 트랙을 포함한 MediaStream을 반환
- 반환값은 Promise 객체(MediaStream)

```javascript
navigator.mediaDevices.getUserMedia(constraints)
.then(function(stream) {
  /* use the stream */
})
.catch(function(err) {
  /* handle the error */
});
```

- 매개변수(constraints)
  - 유형에 대한 요구 사항과 함께 요청할 미디어 유형을 지정하는 개체
  - { audio: true, video: true } : 둘 중 하나 혹은 둘 다를 지정해야 함

```javascript
navigator.mediaDevices
  .getUserMedia({audio: true})
  .then(
    (stream) => {
    // 받아온 MediaStream을 사용
    });
```

<br>

##### 웹소켓(WebSocket)

> https://ko.javascript.info/websocket

- 프로토콜인 웹 소켓을 사용하면 서버와 브라우저 간 연결을 유지한 상태로 데이터를 교환 할 수 있다.
- 데이터는 패킷(packet) 형태로 전달
- 전송은 커넥션 중단과 추가 Http 요청 없이 양방향으로 이루어짐
- 소켓이 정상적으로 만들어지면 4개의 이벤트 사용가능
  - open: 커넥션 제대로 만들어졌을 때 발생
  - message: 데이터 수신했을 때 발생
  - error: 에러 생겼을 때 발생
  - close: 커넥션 종료 때 발생
- 커넥션이 만들어진 상태에서 무언가를 보내고 싶으면 `socket.send(data)` 사용
  - send 메서드는 Blob, ArrayBuffer과 같은 이진 데이터 혹은 텍스트 데이터만 보낼 수 있다.
  - MediaStream을 가공해 Blob 형태로 보내도록 한다.

```javascript
let socket = new WebSocket("wss://javascript.info/article/websocket/demo/hello");

socket.onopen = function(e) {
  alert("[open] 커넥션이 만들어졌습니다.");
  alert("데이터를 서버에 전송해봅시다.");
  socket.send("My name is Bora");
};

socket.onmessage = function(event) {
  alert(`[message] 서버로부터 전송받은 데이터: ${event.data}`);
};

socket.onclose = function(event) {
  if (event.wasClean) {
    alert(`[close] 커넥션이 정상적으로 종료되었습니다(code=${event.code} reason=${event.reason})`);
  } else {
    alert('[close] 커넥션이 죽었습니다.');
  }
};

socket.onerror = function(error) {
  alert(`[error] ${error.message}`);
};
```

- open은 웹소켓이 열리면 음성 녹음을 처리 / send는 서버에 메세지를 보낼 때 / message는 서버로부터 받아온 음성 인식 결과를 사용자에게 보여줄 수 있도록 핸들러 설정 / close와 error는 소켓 연결 종료나 중단 에러 발생했을 때 로그를 찍어주도록 하자

<br>

##### 별개로 작동하는 스레드

- 자바스크립트는 기본적으로 메인스레드가 하나인 싱글스레드 언어
- 브라우저의 렌더링과 같은 메인 스레드의 작업을 방해하지 않으면서, 녹음된 음성의 버퍼 저장과 주기적 전송을 처리해야 할 필요가 있다.
- AudioWorkletNode를 사용하자

<br>

##### Web Audio API

- Web Audio API의 모든 기능은 `AudioContext` 객체를 생성하면서 시작
- `AudioContext`객체는 내부에 여러개의 `Audio Node`들을 가짐

- `Audio Node`들은 각각 하나의 역할을 수행하는 모듈들
  - `GainNode`: 음원의 볼륨 크기 조절
  - `PannerNode`: 음원에 패닝 효과 적용 및 조절
  - `AnalyserNode`: 음원으로부터 데이터 추출

- 노드들은 서로 연결되어 하나의 연결된 그래프(Audio routing graph)를 형성

<br>

##### Javascript로 Web Audio API 사용하기

1. AudioContext 생성

   ```javascript
   var audioCtx = new AudioContext();
   var audioCtx = new (window.AudioContext || window.webkitAudioContext)(); // safari 작동을 위해 window를 붙인다
   ```

2. 오디오 소스 불러오기

- createMediaElementSource: audio 태그로부터 불러오기
- createBufferSource: Raw PCM 데이터로부터 음원 불러오기
- **createMediaStreamSource: 설치된 마이크 등에서 실시간으로 음원 데이터를 받아오는 방법**
- createOscillator: 자바스크립트로 즉석에서 생성된 음원을 사용하는 방법

3. 노드 연결하기

- 순서: source → node → destination(ex. 노트북 스피커)

- ```javascript
  var gainConnected = source.connect(gainNode);
  gainConnected.connect(AudioCtx.destination)
  ```

<br>

##### AudioWorklet

- JavaScript 또는 WebAssembly 로 작성된 사용자 정의 오디오 노드 정의 가능
- `ScriptProcessorNode`의 문제점: 메인 스레드에서 실행되기 때문에 실행을 마치기 전까지 다른 모든 동작을 막음
- AudioWorklet은 메인 스레드에서 떨어져 실행되는 worklet
- 컨텍스트의 audioWorklet.addModule() 메서드를 호출해 오디오 처리 코드를 실행
- addModule()은 오디오 프로세서 구현을 포함하는 Javascript 파일을 로드
- addModule(URL)에서 URL은 추가할 Javascript 파일의 URL이다. 
